{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50d09be",
   "metadata": {},
   "source": [
    "# Ensemble - Boosting Model\n",
    "부스팅(Boosting)이란 단순하고 약한 학습기(Weak Learner)들를 결합해서 보다 정확하고 강력한 학습기(Strong Learner)를 만드는 방식.  \n",
    "정확도가 낮은 하나의 모델을 만들어 학습 시킨뒤, 그 모델의 예측 오류는 두 번째 모델이 보완한다. 이 두 모델을 합치면 처음보다는 정확한 모델이 만들어 진다. 합쳐진 모델의 예측 오류는 다음 모델에서 보완하여 계속 더하는 과정을 반복한다. 즉 **약한 학습기들은 앞 학습기가 만든 오류를 줄이는 방향으로 학습한다**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25c337",
   "metadata": {},
   "source": [
    "# GradientBoosting\n",
    "- 개별 모델로 Decision Tree 를 사용한다. \n",
    "- depth가 깊지 않은 트리를 많이 연결해서 이전 트리의 오차를 보정해 나가는 방식으로 실행한다.\n",
    "- 오차를 보정할 때 경사하강법(Gradient descent)을 사용한다.\n",
    "- 얕은 트리를 많이 연결하여 각각의 트리가 데이터의 일부에 대해 예측을 잘 수행하도록 하고 그런 트리들이 모여 전체 성능을 높이는 것이 기본 아이디어.\n",
    "- 분류와 회귀 둘다 지원하는 모델 (GradientBoostingClassifier, GrandientBoostingRegressor)\n",
    "- 훈련시간이 많이 걸리고, 트리기반 모델의 특성상 희소한 고차원 데이터에서는 성능이 안 좋은 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e5ae4",
   "metadata": {},
   "source": [
    "### 주요 파라미터\n",
    "- **Decision Tree 의 가지치기 관련 매개변수**\n",
    "    - 각각의 decision tree가 복잡한 모델이 되지 않도록 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b7875",
   "metadata": {},
   "source": [
    "- **learning rate**\n",
    "    - 이전 decision tree의 오차를 얼마나 강하게 보정할 것인지 제어하는 값. \n",
    "    - 값이 크면 보정을 강하게 하여 복잡한 모델을 만든다. 학습데이터의 정확도는 올라가지만 과대적합이 날 수있다. \n",
    "    - 값을 작게 잡으면 보정을 약하게 하여 모델의 복잡도를 줄인다. 과대적합을 줄일 수 있지만 성능 자체가 낮아질 수있다.\n",
    "    - 기본값 : 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b82a6d",
   "metadata": {},
   "source": [
    "- **n_estimators**\n",
    "    - decision tree의 개수 지정. 많을 수록 복잡한 모델이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2738ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:04:48.922887Z",
     "start_time": "2022-07-10T07:04:48.907905Z"
    }
   },
   "source": [
    "- **n_iter_no_change, validation_fraction**\n",
    "    - validation_fraction에 지정한 비율만큼 n_iter_no_change에 지정한 반복 횟수동안 검증점수가 좋아 지지 않으면 훈련을 조기 종료한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6005617",
   "metadata": {},
   "source": [
    "- **보통 max_depth를 낮춰 개별 decision tree의 복잡도를 낮춘다. 보통 5가 넘지 않게 설정한다. 그리고 n_estimators를 가용시간, 메모리 한도에 맞춰 크게 설정하고 적절한 learning_rate을 찾는다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459326a",
   "metadata": {},
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b59272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:06:18.055378Z",
     "start_time": "2022-07-10T07:06:18.004515Z"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import print_classification_metrics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c830714",
   "metadata": {},
   "source": [
    "##### GradientBoostingClassifier 모델 생성, 학습, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9244ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:07:01.525787Z",
     "start_time": "2022-07-10T07:07:00.227144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Train\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 1.0\n",
      "재현율/민감도(Recall): 1.0\n",
      "정밀도(Precision): 1.0\n",
      "F1 점수(F1 Score): 1.0\n",
      "==================================================\n",
      "==================================================\n",
      "Test\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.958041958041958\n",
      "재현율/민감도(Recall): 0.9555555555555556\n",
      "정밀도(Precision): 0.9772727272727273\n",
      "F1 점수(F1 Score): 0.9662921348314608\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "pred_train = gb.predict(X_train)\n",
    "pred_test = gb.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_train, pred_train, title='Train')\n",
    "print_classification_metrics(y_test, pred_test, title='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544c37f",
   "metadata": {},
   "source": [
    "##### 하이퍼파라미터 변경에 따른 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7e5ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:07:24.985957Z",
     "start_time": "2022-07-10T07:07:24.794497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Train\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.9953051643192489\n",
      "재현율/민감도(Recall): 1.0\n",
      "정밀도(Precision): 0.9925650557620818\n",
      "F1 점수(F1 Score): 0.9962686567164178\n",
      "==================================================\n",
      "==================================================\n",
      "Test\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.965034965034965\n",
      "재현율/민감도(Recall): 0.9777777777777777\n",
      "정밀도(Precision): 0.967032967032967\n",
      "F1 점수(F1 Score): 0.9723756906077348\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=0, max_depth=1) #learning_rate: 0.1 (기본), n_estimators=100(기본)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "pred_train = gb.predict(X_train)\n",
    "pred_test = gb.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_train, pred_train, title='Train')\n",
    "print_classification_metrics(y_test, pred_test, title='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8e0755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:07:41.029874Z",
     "start_time": "2022-07-10T07:07:39.370756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Train\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 1.0\n",
      "재현율/민감도(Recall): 1.0\n",
      "정밀도(Precision): 1.0\n",
      "F1 점수(F1 Score): 1.0\n",
      "==================================================\n",
      "==================================================\n",
      "Test\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.958041958041958\n",
      "재현율/민감도(Recall): 0.9555555555555556\n",
      "정밀도(Precision): 0.9772727272727273\n",
      "F1 점수(F1 Score): 0.9662921348314608\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=0, max_depth=1, learning_rate=0.1, n_estimators=1000) #learning_rate 기본값: 0.1 => 0.001 (과소적합)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "pred_train = gb.predict(X_train)\n",
    "pred_test = gb.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_train, pred_train, title='Train')\n",
    "print_classification_metrics(y_test, pred_test, title='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237c89b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:07:57.087483Z",
     "start_time": "2022-07-10T07:07:55.275661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Train\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.9953051643192489\n",
      "재현율/민감도(Recall): 1.0\n",
      "정밀도(Precision): 0.9925650557620818\n",
      "F1 점수(F1 Score): 0.9962686567164178\n",
      "==================================================\n",
      "==================================================\n",
      "Test\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.958041958041958\n",
      "재현율/민감도(Recall): 0.9666666666666667\n",
      "정밀도(Precision): 0.9666666666666667\n",
      "F1 점수(F1 Score): 0.9666666666666667\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=0, max_depth=1, learning_rate=0.01, n_estimators=1000) #learning_rate 기본값: 0.1 => 0.01 (과소적합)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "pred_train = gb.predict(X_train)\n",
    "pred_test = gb.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_train, pred_train, title='Train')\n",
    "print_classification_metrics(y_test, pred_test, title='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a05a65",
   "metadata": {},
   "source": [
    "##### Feature 중요도를 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24912cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:08:32.610547Z",
     "start_time": "2022-07-10T07:08:32.578658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00151889, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00446665, 0.16350925, 0.        , 0.        ,\n",
       "       0.00044232, 0.        , 0.        , 0.00377378, 0.00122931,\n",
       "       0.        , 0.00041146, 0.        , 0.        , 0.        ,\n",
       "       0.09167029, 0.01931462, 0.30713717, 0.10577961, 0.00404029,\n",
       "       0.        , 0.00739352, 0.28808604, 0.0012268 , 0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c64e72c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:08:46.787626Z",
     "start_time": "2022-07-10T07:08:45.258690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst perimeter            0.307137\n",
       "worst concave points       0.288086\n",
       "mean concave points        0.163509\n",
       "worst area                 0.105780\n",
       "worst radius               0.091670\n",
       "worst texture              0.019315\n",
       "worst concavity            0.007394\n",
       "mean concavity             0.004467\n",
       "worst smoothness           0.004040\n",
       "area error                 0.003774\n",
       "mean texture               0.001519\n",
       "smoothness error           0.001229\n",
       "worst symmetry             0.001227\n",
       "radius error               0.000442\n",
       "concavity error            0.000411\n",
       "worst compactness          0.000000\n",
       "fractal dimension error    0.000000\n",
       "mean radius                0.000000\n",
       "compactness error          0.000000\n",
       "symmetry error             0.000000\n",
       "concave points error       0.000000\n",
       "perimeter error            0.000000\n",
       "texture error              0.000000\n",
       "mean fractal dimension     0.000000\n",
       "mean symmetry              0.000000\n",
       "mean compactness           0.000000\n",
       "mean smoothness            0.000000\n",
       "mean area                  0.000000\n",
       "mean perimeter             0.000000\n",
       "worst fractal dimension    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fi = pd.Series(gb.feature_importances_, index=data['feature_names'])\n",
    "fi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb06f94",
   "metadata": {},
   "source": [
    "### GridSearchCV 이용해 최적의 하이퍼파라미터 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701b8e8",
   "metadata": {},
   "source": [
    "##### RandomizedSearchCV 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84d8e87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:10:05.293296Z",
     "start_time": "2022-07-10T07:10:05.275344Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param = {\n",
    "    'n_estimators':range(500, 1001, 100),\n",
    "    'learning_rate':[0.001, 0.05, 0.01, 0.1, 0.5], \n",
    "    'max_depth':[1,2,3],\n",
    "    'subsample':[0.5, 0.7, 0.9, 1]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(GradientBoostingClassifier(random_state=0),\n",
    "                        param,\n",
    "                        cv=4, \n",
    "                        n_iter=60, \n",
    "                        scoring='accuracy', \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2cd19",
   "metadata": {},
   "source": [
    "##### 학습, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "223fa039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:11:16.706580Z",
     "start_time": "2022-07-10T07:10:17.145762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=GradientBoostingClassifier(random_state=0),\n",
       "                   n_iter=60, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.05, 0.01,\n",
       "                                                          0.1, 0.5],\n",
       "                                        'max_depth': [1, 2, 3],\n",
       "                                        'n_estimators': range(500, 1001, 100),\n",
       "                                        'subsample': [0.5, 0.7, 0.9, 1]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d3125",
   "metadata": {},
   "source": [
    "##### best estimator 조회 및 Test set 최종평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0793a36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:11:24.591795Z",
     "start_time": "2022-07-10T07:11:24.569853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.5, 'n_estimators': 1000, 'max_depth': 2, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464d2815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:11:26.206571Z",
     "start_time": "2022-07-10T07:11:26.185626Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = rs.best_estimator_\n",
    "pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce188d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:11:27.281971Z",
     "start_time": "2022-07-10T07:11:27.265004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "best_model\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.958041958041958\n",
      "재현율/민감도(Recall): 0.9666666666666667\n",
      "정밀도(Precision): 0.9666666666666667\n",
      "F1 점수(F1 Score): 0.9666666666666667\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_test, pred_test, \"best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59f80a",
   "metadata": {},
   "source": [
    "# XGBoost(Extra Gradient Boost)\n",
    "- https://readthedocs.org/projects/xgboost/\n",
    "- Gradient Boost 알고리즘을 기반으로 개선해서 분산환경에서도 실행할 수 있도록 구현 나온 모델.\n",
    "- Gradient Boost의 단점인 느린수행시간을 해결하고 과적합을 제어할 수 있는 규제들을 제공하여 성능을 높임.\n",
    "- 회귀와 분류 모두 지원한다.\n",
    "- 캐글 경진대회에서 상위에 입상한 데이터 과학자들이 사용한 것을 알려저 유명해짐.\n",
    "- 두가지 개발 방법\n",
    "    - [Scikit-learn 래퍼 XGBoost 모듈 사용](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "    - [파이썬 래퍼 XGBoost 모듈 사용](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.training)\n",
    "- 설치\n",
    "``\n",
    "conda install -y -c anaconda py-xgboost\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c2f30",
   "metadata": {},
   "source": [
    "## Scikit-learn 래퍼(Wrapper) XGBoost\n",
    "- XGBoost를 Scikit-learn프레임워크와 연동할 수 있도록 개발됨.\n",
    "- Scikit-learn의 Estimator들과 동일한 패턴으로 코드를 작성할 수 있다.\n",
    "- GridSearchCV나 Pipeline 등 Scikit-learn이 제공하는 다양한 유틸리티들을 사용할 수 있다.\n",
    "- XGBClassifier: 분류\n",
    "- XGBRegressor : 회귀 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd6bd8",
   "metadata": {},
   "source": [
    "### 주요 매개변수\n",
    "- learning_rate : 학습률, 보통 0.01 ~ 0.2 사이의 값 사용\n",
    "- n_estimators : week tree 개수\n",
    "- Decision Tree관련 하이퍼파라미터들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40621333",
   "metadata": {},
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0bb1e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:15:58.187245Z",
     "start_time": "2022-07-10T07:15:57.654472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "==================================================\n",
      "XGB Train\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.9953051643192489\n",
      "재현율/민감도(Recall): 0.9962546816479401\n",
      "정밀도(Precision): 0.9962546816479401\n",
      "F1 점수(F1 Score): 0.9962546816479401\n",
      "==================================================\n",
      "==================================================\n",
      "XGB Test\n",
      "--------------------------------------------------\n",
      "정확도(Accuracy): 0.951048951048951\n",
      "재현율/민감도(Recall): 0.9555555555555556\n",
      "정밀도(Precision): 0.9662921348314607\n",
      "F1 점수(F1 Score): 0.9608938547486034\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate=0.01, max_depth=2, random_state=0)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "pred_train = xgb.predict(X_train)\n",
    "pred_test = xgb.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_train, pred_train, \"XGB Train\")\n",
    "print_classification_metrics(y_test, pred_test, 'XGB Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53228795",
   "metadata": {},
   "source": [
    "# Ensemble - Voting 방식\n",
    "- 서로 다른 종류의 알고리즘들을 결합하여 다수결 방식으로 최종 결과를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66cbd1",
   "metadata": {},
   "source": [
    "## Voting의 유형 (분류)\n",
    "1. **hard voting**\n",
    "    - 다수의 추정기가 결정한 예측값들 중 많은 것을 선택하는 방식\n",
    "2. **soft voting**\n",
    "    - 다수의 추정기에서 각 레이블별 예측한 확률들의 평균을 내서 높은 레이블값을 결과값으로 선택하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8a7d1",
   "metadata": {},
   "source": [
    "- 일반적으로 soft voting이 성능이 더 좋다.    \n",
    "- Voting은 성향이 다르면서 비슷한 성능을 가진 모델들을 묶었을때 가장 좋은 성능을 낸다.\n",
    "    - 성능이 비슷하면서 다른 예측을 하는 모델들을 묶었을 때 가장 좋은 성능을 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dd751",
   "metadata": {},
   "source": [
    "## VotingClassifier 클래스 이용\n",
    "- 매개변수\n",
    "    - estimators : 앙상블할 모델들 설정.  (\"추정기이름\", 추정기) 의 튜플을 리스트로 묶어서 전달\n",
    "    - voting: voting 방식. hard(기본값), soft  지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78b502",
   "metadata": {},
   "source": [
    "##### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45425f5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:22:57.103071Z",
     "start_time": "2022-07-10T07:22:57.079132Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296412a",
   "metadata": {},
   "source": [
    "##### Data전처리\n",
    "- SVM, KNN, LogisticRegression은 Feature Scaling 전처리 데이터를 사용\n",
    "- Random Forest, XGBoost는 Decision Tree기반이므로 Feature Scaling이 필요없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b097f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:23:28.466595Z",
     "start_time": "2022-07-10T07:23:28.457459Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ec9e4",
   "metadata": {},
   "source": [
    "##### 모델들 생성, 학습, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc81aef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:23:44.125380Z",
     "start_time": "2022-07-10T07:23:44.113411Z"
    }
   },
   "outputs": [],
   "source": [
    "# 평가함수\n",
    "def print_metrics(y, pred, title=None):\n",
    "    acc = accuracy_score(y, pred)\n",
    "    if title:\n",
    "        print(title)\n",
    "    print(\"정확도: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b11582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:23:49.572914Z",
     "start_time": "2022-07-10T07:23:48.618069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# 모델들 객체를 생성\n",
    "svc = SVC(random_state=0, probability=True) \n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0)\n",
    "lr = LogisticRegression(max_iter=1000, random_state=0)\n",
    "xgb = XGBClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# 각 모델들을 학습\n",
    "svc.fit(X_train_scaled, y_train) # Feature Scaling 된 X_train\n",
    "knn.fit(X_train_scaled, y_train) # Feature Scaling 된 X_train\n",
    "rf.fit(X_train, y_train)\n",
    "lr.fit(X_train_scaled, y_train) # Feature Scaling 된 X_train\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# 추론\n",
    "pred_train_svc = svc.predict(X_train_scaled)\n",
    "pred_train_knn = knn.predict(X_train_scaled)\n",
    "pred_train_rf = rf.predict(X_train)\n",
    "pred_train_lr = lr.predict(X_train_scaled)\n",
    "pred_train_xgb = xgb.predict(X_train)\n",
    "\n",
    "pred_test_svc = svc.predict(X_test_scaled)\n",
    "pred_test_knn = knn.predict(X_test_scaled)\n",
    "pred_test_rf = rf.predict(X_test)\n",
    "pred_test_lr = lr.predict(X_test_scaled)\n",
    "pred_test_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2ad2f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:25:17.494742Z",
     "start_time": "2022-07-10T07:25:17.480779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SVC\n",
      "정확도:  0.9929577464788732\n",
      "Train KNN\n",
      "정확도:  0.9788732394366197\n",
      "Train RF\n",
      "정확도:  0.9976525821596244\n",
      "Train LogisticRegression\n",
      "정확도:  0.9906103286384976\n",
      "Train XGB\n",
      "정확도:  1.0\n"
     ]
    }
   ],
   "source": [
    "# trainset 평가\n",
    "print_metrics(y_train, pred_train_svc, \"Train SVC\")\n",
    "print_metrics(y_train, pred_train_knn, \"Train KNN\")\n",
    "print_metrics(y_train, pred_train_rf, \"Train RF\")\n",
    "print_metrics(y_train, pred_train_lr, \"Train LogisticRegression\")\n",
    "print_metrics(y_train, pred_train_xgb, 'Train XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c322112c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:25:24.546735Z",
     "start_time": "2022-07-10T07:25:24.528783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test SVC\n",
      "정확도:  0.958041958041958\n",
      "Test KNN\n",
      "정확도:  0.951048951048951\n",
      "Test RF\n",
      "정확도:  0.9440559440559441\n",
      "Test LogisticRegression\n",
      "정확도:  0.958041958041958\n",
      "Test XGBoost\n",
      "정확도:  0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "# testset 평가\n",
    "print_metrics(y_test, pred_test_svc, 'Test SVC')\n",
    "print_metrics(y_test, pred_test_knn, 'Test KNN')\n",
    "print_metrics(y_test, pred_test_rf, 'Test RF')\n",
    "print_metrics(y_test, pred_test_lr, 'Test LogisticRegression')\n",
    "print_metrics(y_test, pred_test_xgb, 'Test XGBoost')\n",
    "\n",
    "# 1. 성능이 비슷?\n",
    "# 2. 결과에 차이가 있나? (다른 예측?) ==> ?(상관관계 분석)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbfac1",
   "metadata": {},
   "source": [
    "### 앙상블 상관관계\n",
    "- 상관관계가 높은 모델을 앙상블에 포함시키는 것은 바람직 하지 않다.\n",
    "- 모델간의 상관관계가 높다는 것은 두 모델이 동일한 예측을 한다는 것이다. 같은 예측을 하는 모델은 의미가 없다. \n",
    "- Voting방식(다수결 투표방식)의 앙상블은 각각 좋은 성능을 내지만 다른 예측을 하는 다양한 모델을 모아서 하는 것이 좋다.  대부분의 모델들이 동일한 예측을 만든다면 새로운 모델을 추가해 얻는 이득이 적다.\n",
    "\n",
    "#### 모델간의 상관관계 확인\n",
    "- 각 모델의 예측 결과를 이용해 상관계수를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96e4de56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:26:15.479290Z",
     "start_time": "2022-07-10T07:26:15.457348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  10 100]\n",
      " [  2  20 200]\n",
      " [  3  30 300]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([10,20,30])\n",
    "c = np.array([100,200,300])\n",
    "\n",
    "# 1차원 배열들을 2차원 배열이 되도록 합치기. 1축 기준으로 합칠때  c_[배열, 배열, 배열]\n",
    "print(np.c_[a, b, c])\n",
    "# 1차원 배열들을 0축을 기준으로 합치기. r_[배열, 배열, 배열]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "708002c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:27:03.638266Z",
     "start_time": "2022-07-10T07:27:03.601068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVM  KNN  RandomForest  LogisticRegression  XGBoost\n",
       "0    1    1             1                   1        1\n",
       "1    0    0             0                   0        0\n",
       "2    1    1             1                   1        1\n",
       "3    1    1             1                   1        1\n",
       "4    1    1             1                   1        1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Train set에대한 예측 결과를 기준\n",
    "df = pd.DataFrame(np.c_[pred_train_svc,pred_train_knn,pred_train_rf ,pred_train_lr,pred_train_xgb], \n",
    "                  columns=[\"SVM\", \"KNN\", 'RandomForest', 'LogisticRegression', 'XGBoost'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbb52718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:28:31.220412Z",
     "start_time": "2022-07-10T07:28:31.200466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969819</td>\n",
       "      <td>0.989940</td>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.984941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.969819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959758</td>\n",
       "      <td>0.974829</td>\n",
       "      <td>0.954799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.989940</td>\n",
       "      <td>0.959758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984902</td>\n",
       "      <td>0.994989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.974829</td>\n",
       "      <td>0.984902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.984941</td>\n",
       "      <td>0.954799</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.979929</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SVM       KNN  RandomForest  LogisticRegression  \\\n",
       "SVM                 1.000000  0.969819      0.989940            0.994976   \n",
       "KNN                 0.969819  1.000000      0.959758            0.974829   \n",
       "RandomForest        0.989940  0.959758      1.000000            0.984902   \n",
       "LogisticRegression  0.994976  0.974829      0.984902            1.000000   \n",
       "XGBoost             0.984941  0.954799      0.994989            0.979929   \n",
       "\n",
       "                     XGBoost  \n",
       "SVM                 0.984941  \n",
       "KNN                 0.954799  \n",
       "RandomForest        0.994989  \n",
       "LogisticRegression  0.979929  \n",
       "XGBoost             1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 feature가의 상관계수 계산 - df.corr()\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2f7478a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:28:57.148813Z",
     "start_time": "2022-07-10T07:28:57.133853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVM  KNN  RandomForest  LogisticRegression  XGBoost\n",
       "0    1    1             1                   1        1\n",
       "1    0    0             0                   0        0\n",
       "2    0    0             0                   0        0\n",
       "3    1    1             1                   1        1\n",
       "4    0    0             0                   0        0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(np.c_[pred_test_svc,pred_test_knn,pred_test_rf ,pred_test_lr,pred_test_xgb], \n",
    "                  columns=[\"SVM\", \"KNN\", 'RandomForest', 'LogisticRegression', 'XGBoost'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8e42078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:28:57.335436Z",
     "start_time": "2022-07-10T07:28:57.313474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895618</td>\n",
       "      <td>0.880084</td>\n",
       "      <td>0.970021</td>\n",
       "      <td>0.940042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.895618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926280</td>\n",
       "      <td>0.895618</td>\n",
       "      <td>0.895618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.880084</td>\n",
       "      <td>0.926280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880084</td>\n",
       "      <td>0.910063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.970021</td>\n",
       "      <td>0.895618</td>\n",
       "      <td>0.880084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.940042</td>\n",
       "      <td>0.895618</td>\n",
       "      <td>0.910063</td>\n",
       "      <td>0.940042</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SVM       KNN  RandomForest  LogisticRegression  \\\n",
       "SVM                 1.000000  0.895618      0.880084            0.970021   \n",
       "KNN                 0.895618  1.000000      0.926280            0.895618   \n",
       "RandomForest        0.880084  0.926280      1.000000            0.880084   \n",
       "LogisticRegression  0.970021  0.895618      0.880084            1.000000   \n",
       "XGBoost             0.940042  0.895618      0.910063            0.940042   \n",
       "\n",
       "                     XGBoost  \n",
       "SVM                 0.940042  \n",
       "KNN                 0.895618  \n",
       "RandomForest        0.910063  \n",
       "LogisticRegression  0.940042  \n",
       "XGBoost             1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d974426",
   "metadata": {},
   "source": [
    "##### VotingClassifier로 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa733b5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:29:38.656848Z",
     "start_time": "2022-07-10T07:29:38.640895Z"
    }
   },
   "outputs": [],
   "source": [
    "# 앙상블할 모델들 리스트 \n",
    "estimators = [\n",
    "    ('knn', knn),\n",
    "    ('xgb', xgb), \n",
    "    ('random forest', rf), \n",
    "    ('svm', svc)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fd5ad",
   "metadata": {},
   "source": [
    "###### hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3ea7e90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:30:03.689397Z",
     "start_time": "2022-07-10T07:30:02.936439Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "정확도:  0.9953051643192489\n",
      "정확도:  0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(estimators) #hard voting\n",
    "\n",
    "voting.fit(X_train_scaled, y_train)  #각 모델을 학습시킨다.\n",
    "\n",
    "pred_train = voting.predict(X_train_scaled)\n",
    "pred_test = voting.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(y_train, pred_train)\n",
    "print_metrics(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b0518",
   "metadata": {},
   "source": [
    "###### soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a26d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:30:26.999095Z",
     "start_time": "2022-07-10T07:30:26.272434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "정확도:  0.9953051643192489\n",
      "정확도:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(estimators, voting='soft') #soft voting (확률 평균으로 결과를 예측)\n",
    "voting.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred_train = voting.predict(X_train_scaled)\n",
    "pred_test = voting.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(y_train, pred_train)\n",
    "print_metrics(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4e1ce",
   "metadata": {},
   "source": [
    "##### Pipeline을 이용해 데이터전처리와 모델 묶어서 처리\n",
    "- KNN, SVM: Feature Scaling이 필요 => Pipeline\n",
    "- XGBoost, Random Forest:  Feature Scaling 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7f06ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-10T07:34:53.965288Z",
     "start_time": "2022-07-10T07:34:53.244085Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "정확도:  0.9953051643192489\n",
      "정확도:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "# 파이프라인 생성\n",
    "order_knn = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "]\n",
    "order_svm = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(random_state=0, probability=True))\n",
    "]\n",
    "\n",
    "knn_pl = Pipeline(order_knn)  # make_pipeline(SS(), KNN())\n",
    "svm_pl = Pipeline(order_svm)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(max_depth=2, random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0)\n",
    "\n",
    "estimators = [\n",
    "    ('knn', knn_pl), ('svm', svm_pl), ('xgb', xgb), ('random forest', rf)\n",
    "]\n",
    "voting = VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "print_metrics(y_train, voting.predict(X_train))\n",
    "print_metrics(y_test, voting.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
