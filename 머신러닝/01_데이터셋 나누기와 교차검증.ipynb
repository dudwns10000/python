{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2935ae39",
   "metadata": {},
   "source": [
    "# 데이터셋(Dataset)\n",
    "- **Train 데이터셋 (훈련/학습 데이터셋)**\n",
    "    - 모델을 학습시킬 때 사용할 데이터셋.\n",
    "- **Validation 데이터셋 (검증 데이터셋)**\n",
    "    - 모델의 성능 중간 검증을 위한 데이터셋\n",
    "- **Test 데이터셋 (평가 데이터셋)**\n",
    "    - 모델의 성능을 최종적으로 측정하기 위한 데이터셋\n",
    "    - **Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용되야 한다.**\n",
    "        - 모델을 훈련하고 평가했을때 원하는 성능이 나오지 않으면 데이터나 모델 학습을 위한 설정(하이퍼파라미터)을 수정한 뒤에 다시 훈련시키고 평가를 하게 된다. 원하는 성능이 나올때 까지 설정변경->훈련->평가를 반복하게 된다. \n",
    "        - 위 사이클을 반복하게 되면 평가결과를 바탕으로 설정을 변경하게 되므로 모델이 평가할 때 사용한 데이터셋(Test set)에 모델이 맞춰서 훈련하는 것과 동일한 효과를 내게 된다.(설정을 변경하는 이유가 Test set에 대한 결과를 좋게 만들기 위해 변경하므로) 그래서 Train dataset과 Test dataset 두개의 데이터셋만 사용하게 되면 모델의 성능을 제대로 평가할 수 없게 된다. 그래서 데이터셋을 train 세트, validation 세터, test 세트로 나눠 train set 와 validation set으로 모델을 최적화 한 뒤 마지막에 test set으로 최종 평가를 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850c6ff",
   "metadata": {},
   "source": [
    "# Data 분리 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3097e",
   "metadata": {},
   "source": [
    "## Hold Out\n",
    "- 데이터 셋을 Train set, Validation set, Test set으로 나눈다.\n",
    "- sklearn.medel_selection.train_test_split() 함수 사용\n",
    "    - 하나의 dataset을 2 분할 해 주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8d6ba",
   "metadata": {},
   "source": [
    "### Hold out 방식의 단점\n",
    "- train/validation/test 셋이 어떻게 나눠 지냐에 따라 결과가 달라진다.\n",
    "    - 데이터가 충분히 많을때는 변동성이 흡수되 괜찮으나 적을 경우 문제가 발생할 수 있다.\n",
    "        - 이상치에 대한 영향을 많이 받는다.\n",
    "        - 다양한 패턴을 찾을 수가 없기 때문에 새로운 데이터에 대한 예측 성능이 떨어지게 된다.\n",
    "        \n",
    "- **Hold out 방식은 (다양한 패턴을 가진) 데이터의 양이 많을 경우에 사용한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b8aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d601765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)   #return_X_y=True: Feature와 target(label) 배열만 tuple에 묶어서 반환.\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5425b",
   "metadata": {},
   "source": [
    "### Train/Test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf4655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4) (105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, # Feature(Input, X)\n",
    "                                                   y, # Target(Label, Output, y)\n",
    "                                                   test_size=0.3, # test 셋의 비율\n",
    "                                                   random_state=0,# random seed 값 => shuffle을 random하게 한다.\n",
    "                                                   stratify=y)\n",
    "                                                   # **분류문제**에서 분할된 데이터셋의 class별 데이터수의 비율을 원본데이터셋과 동일하게 만들어준다.\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c54f42",
   "metadata": {},
   "source": [
    "### Train/Validation/Test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b69e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 4), (24, 4), (30, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 Dataset => Train/Test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "# Train set => Train/Validation 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, #Train set\n",
    "                                                  test_size=0.2, stratify=y_train, random_state=0)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f32846",
   "metadata": {},
   "source": [
    "### 모델생성, 평가\n",
    "하이퍼파라미터(hyper parameter) 튜닝(tuning)\n",
    "- max_depth=1 => 0.66666\n",
    "- max_depth=2 => 1\n",
    "\n",
    "> 하이퍼파라미터: 모델생성할때 우리가 설정해주는 설정값으로 모델 성능에 영향을 준다.\n",
    "> 하이퍼파라미터 튜닝: 모델의 성능이 좋아지도록 하이퍼파라미터 값을 변경하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ebc4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 정확도:  1.0\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0, max_depth= 2) \n",
    "\n",
    "# 학습-train\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# 평가-validation\n",
    "pred_val = tree.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, pred_val)\n",
    "\n",
    "print(\"val 정확도: \", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf606a76",
   "metadata": {},
   "source": [
    "### test set으로 최종검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb548972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88215958",
   "metadata": {},
   "source": [
    "## K-겹 교차검증 (K-Fold Cross Validation) \n",
    "1. 데이터셋을 설정한 K 개로 나눈다.\n",
    "1. K개 중 하나를 검증세트로 나머지를 훈련세트로 하여 모델을 학습시키고 평가한다. \n",
    "1. K개 모두가 한번씩 검증세트가 되도록 K번 반복하여 모델을 학습시킨 뒤 나온 평가지표들을 평균내서 모델의 성능을 평가한다.\n",
    "- 데이터양이 충분치 않을때 사용한다.\n",
    "- 보통 Fold를 나눌때 2.5:7.5 또는 2:8 비율이 되게 하기 위해 4개 또는 5개 fold로 나눈다. \n",
    "- 종류\n",
    "    - **KFold**\n",
    "        - 회귀문제의 Dataset을 분리할 때 사용\n",
    "    - **StratifiedKFold**\n",
    "        - 분류문제의 Dataset을 분리할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bb245",
   "metadata": {},
   "source": [
    "### KFold\n",
    "- 지정한 개수(K)만큼 분할한다.\n",
    "- Raw dataset의 순서를 유지하면서 지정한 개수로 분할한다.\n",
    "- 회귀 문제일때 사용한다.\n",
    "- KFold(n_splits=K)\n",
    "    - 몇개의 Fold로 나눌지 지정\n",
    "- KFold객체.split(데이터셋)\n",
    "    - 데이터셋을 지정한 K개 나눴을때 train/test set에 포함될 데이터의 **index**들을 반환하는 generator 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd2be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold   #KFold 클래스 - train_test_split()와 동일한 모듈\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a8e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 fold별 검증 결과들을 담을 리스트\n",
    "acc_train_list = [] # trainset으로 평가한 결과\n",
    "acc_test_list = []  # test dataset으로 평가한 결과\n",
    "\n",
    "# KFold 객체 생성 - 3개 fold\n",
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kfold.split(X):   #split() index를 제공하는 generator생성 => 튜플 (train set index,  test set index)\n",
    "    \n",
    "    # KFold generator가 제공한 index를 이용해 data 조회\n",
    "    X_train, y_train = X[train_index], y[train_index] #train set 추출\n",
    "    X_test, y_test = X[test_index], y[test_index]     #test set 추출\n",
    "    \n",
    "    # 모델생성\n",
    "    tree = DecisionTreeClassifier()\n",
    "    \n",
    "    # 학습\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # 추론\n",
    "    pred_train = tree.predict(X_train)\n",
    "    pred_test = tree.predict(X_test)\n",
    "    \n",
    "    # 평가 - 정확도 \n",
    "    acc_train = accuracy_score(y_train, pred_train)  #(정답, 예측값)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "    acc_train_list.append(acc_train)  #평가결과들을 list에 append(추가)\n",
    "    acc_test_list.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e446affc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, 1.0], 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train_list, np.mean(acc_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f98027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 0.0, 0.0], 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test_list, np.mean(acc_test_list) \n",
    "# 정확도 0.0 : 한개도 못맞췄다. ===> 분류문제일 경우 KFold(회귀)를 사용하지 말고 StratifiedKFold를 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31522f4",
   "metadata": {},
   "source": [
    "### StratifiedKold\n",
    "- 나뉜 fold 들에 label들이 같은(또는 거의 같은) 비율로 구성 되도록 나눈다. \n",
    "- 각각의 클래스 별로 각각 순서대로 나눈다.\n",
    "- 분류문제일 때 사용한다.\n",
    "- StratifiedKold(n_splits=K)\n",
    "    - 몇개의 Fold로 나눌지 지정\n",
    "- StratifiedKold객체.split(X, y)\n",
    "    - 데이터셋을 지정한 K개 나눴을때 train/test set에 포함될 데이터의 index들을 반환하는 generator 생성\n",
    "    - input(X)와 output(y) dataset을  전달한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e78be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "525c94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더별 검증 결과들을 담을 list\n",
    "acc_train_list = []\n",
    "acc_test_list = []\n",
    "\n",
    "s_fold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in s_fold.split(X, y):  # 반복-튜플 (train index,  test index)\n",
    "    \n",
    "    # train/test 데이터셋 추출\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    \n",
    "    # 모델생성\n",
    "    tree = DecisionTreeClassifier()\n",
    "    \n",
    "    # 학습\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # 추론\n",
    "    pred_train = tree.predict(X_train)\n",
    "    pred_test = tree.predict(X_test)\n",
    "    \n",
    "    # 평가\n",
    "    acc_train = accuracy_score(y_train, pred_train)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "    \n",
    "    acc_train_list.append(acc_train)\n",
    "    acc_test_list.append(acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c12fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0] 1.0\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_list, np.mean(acc_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c020a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98, 0.92, 1.0] 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(acc_test_list, np.mean(acc_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3bd8f",
   "metadata": {},
   "source": [
    "## cross_val_score( )\n",
    "- 데이터셋을 K개로 나누고 K번 반복하면서 평가하는 작업을 처리해 주는 함수\n",
    "- 주요매개변수\n",
    "    - estimator: 모델객체\n",
    "    - X: feature(input data)\n",
    "    - y: label(output data)\n",
    "    - scoring: 평가지표\n",
    "    - cv: 나눌 개수 (K)\n",
    "        - int: 개수\n",
    "        - KFold, StratifiedKFold 객체\n",
    "- 반환값: array - 각 반복마다의 평가점수    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b558ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 0.94 0.98]\n",
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# scores = cross_val_score(dt_clf , data , label , scoring='accuracy', cv=3)\n",
    "# kfold = KFold(n_splits=3)\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "scores = cross_val_score(dt_clf , data , label , scoring='accuracy', cv=kfold)  \n",
    "print(scores)\n",
    "print('교차 검증별 정확도:',np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
